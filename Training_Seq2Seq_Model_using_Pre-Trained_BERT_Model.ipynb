{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training_Seq2Seq_Model_using_Pre-Trained_BERT_Model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMNRw65U7AvtnsOgTDEwDKL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fb866213ee5d4b028f9cae38f6bfbb95":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c7adc0701d3c43beadfb0a20b14c195c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_07823a28544447fabf67076386526043","IPY_MODEL_22120f1dcdb14de299f3b888a0879fdc"]}},"c7adc0701d3c43beadfb0a20b14c195c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"07823a28544447fabf67076386526043":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d247dd05126447138ccd31faad561306","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_706e481d992a40ada71c3187ec945407"}},"22120f1dcdb14de299f3b888a0879fdc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_77a4c0502a374e8290cee083e4e2aa95","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.63MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f2a431b80e8a4b9995db704129cb8408"}},"d247dd05126447138ccd31faad561306":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"706e481d992a40ada71c3187ec945407":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"77a4c0502a374e8290cee083e4e2aa95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f2a431b80e8a4b9995db704129cb8408":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5882ff380fae417ab5ce2913b710c189":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_54b27e2d2dec4d1caab0996e999bbc2a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8d54fe1d82654cfb9a429a11315d5b0a","IPY_MODEL_bfee81ff4dd94d278e15ac121e7056dd"]}},"54b27e2d2dec4d1caab0996e999bbc2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d54fe1d82654cfb9a429a11315d5b0a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_70abe934f6f94a5cbde177523d2f8a90","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_675d2a83b5d8480080675859740649b2"}},"bfee81ff4dd94d278e15ac121e7056dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_02628033efb0456aa305f653532bae9c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 1.36kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a616df17a584433a7457df21a65846c"}},"70abe934f6f94a5cbde177523d2f8a90":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"675d2a83b5d8480080675859740649b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"02628033efb0456aa305f653532bae9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7a616df17a584433a7457df21a65846c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1cbbfe48a8a34cd38f3eea263edad7c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7b42fed2bf6a4f998e53ffddf14ed505","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a2dee824b24a4db1ba4f44261eb8871f","IPY_MODEL_5495a110ee3d4f0e99c28cb559715fd6"]}},"7b42fed2bf6a4f998e53ffddf14ed505":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2dee824b24a4db1ba4f44261eb8871f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4eeadd0a9dfb468ca08abe3daf787563","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1e877ce36754b09a380472155c8a3db"}},"5495a110ee3d4f0e99c28cb559715fd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c88d12a91d894734a5951c73d9413789","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:07&lt;00:00, 56.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7495882d94444e1bb401eed94a0a6ac1"}},"4eeadd0a9dfb468ca08abe3daf787563":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d1e877ce36754b09a380472155c8a3db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c88d12a91d894734a5951c73d9413789":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7495882d94444e1bb401eed94a0a6ac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"FhTShpWlXF-r"},"source":["Reference:\n","\n","https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/6%20-%20Transformers%20for%20Sentiment%20Analysis.ipynb\n","\n","https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb"]},{"cell_type":"code","metadata":{"id":"DaRUvf4NI-T3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615816109958,"user_tz":-330,"elapsed":31510,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"9a1dd7e6-7d66-46dc-a5ce-381a8e9c3c0d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mnKm7cWxJhWR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615816128797,"user_tz":-330,"elapsed":4443,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"e8c0f317-ab74-4c95-82a6-9857143b1144"},"source":["!pip install Unidecode"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting Unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n","\r\u001b[K     |█▍                              | 10kB 14.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 15.2MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 10.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 81kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 92kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 122kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 133kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 153kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 163kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 174kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 184kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 194kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 204kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 215kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 225kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 235kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 6.9MB/s \n","\u001b[?25hInstalling collected packages: Unidecode\n","Successfully installed Unidecode-1.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rZlnfZqsJlKe"},"source":["# Imports\n","import numpy as np\n","import pandas as pd\n","import spacy\n","import random\n","import re\n","import math\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchtext\n","#from torchtext.data import Field,BucketIterator,TabularDataset\n","from torchtext.legacy.data import Field,BucketIterator,TabularDataset\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fkN6rHf3JrbB"},"source":["torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y0ylC5tL_SBg"},"source":["# Data Cleansing"]},{"cell_type":"code","metadata":{"id":"a4ed-77NJuWv"},"source":["# replacing contraction words\n","\n","contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\",'i\\'m':'i am', \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cJhRDdTVJybv"},"source":["# dealing with spl characters\n","punct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';',  '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n"," '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n"," '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n"," '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n"," '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√','∞','θ','÷','α','•','à','−','β','∅','³','π','‘','₹','´','°','™','√²','—–' ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKXf814eKPm9"},"source":["punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpFMo0k5KPeb"},"source":["missplet_dict = {'didnt':'did not',\n"," \"i'm\": 'i am',\n"," 'doesnt' : 'does not',\n"," 'isnt' : 'is not',\n"," 'upvote' : 'up vote',\n"," 'wasnt' : 'was not',\n"," 'remindme': 'remind me',\n"," 'lt3' : 'love',\n"," 'upvotes' : 'up votes',\n"," 'shouldnt' : 'should not',\n"," 'hasnt' : 'has not',\n"," 'downvoted' : 'down voted',\n"," 'howd' : ' how do you do',\n"," 'upvoted' : 'up voted',\n"," 'rcasualconversation' : 'casual conversation',\n"," 'cakeday' : 'cake day',\n"," 'downvote' : 'down vote',\n"," 'whatre' : 'what are',\n"," 'contenderwhat' : 'contender what',\n"," 'downvotes' : 'down votes',\n"," 'heshe' : 'he she',\n"," 'tldr' : 'too long did not read',\n"," 'ftfy' : 'Fixed That For You',\n"," 'wbu' : 'what about you',\n"," 'thatd' : 'that would',\n"," 'welp' : 'well',\n"," 'ikr' : 'i know right',\n"," 'realise' : 'realize',\n"," 'thatll' : 'that will',\n"," 'upvoting' : 'up voting',\n"," 'whatd' : ' what did',\n"," 'grey': 'gray',\n"," 'yesno' : 'yes no',\n"," 'flavour' : 'flavor',\n"," 'tooslowly' : 'too slowly',\n"," 'realised' : 'realized',\n"," 'learnt' : 'learn',\n"," 'answers—comment' :  'answers comment',\n"," 'gorillaz' : 'gorilla',\n"," '“fuck' : 'fuck',\n"," 'accomplishedbeen' : 'accomplished been',\n"," 'whyd' : 'why did',\n"," 'edm' : 'electronic dance music',\n"," 'linkin' : 'linking',\n"," 'hbu' : 'how about you',\n"," 'mustve' : 'must have',\n"," 'whered' : 'where did',\n"," 'continuein' : 'continuing',\n"," 'welldo' : 'well done',\n"," 'downvoter' : 'down voter',\n"," 'friendo' : 'friend',\n"," '“fixed' : 'fixed',\n"," 'yknow' : 'you know',\n"," 'programme' : 'program',\n"," 'heya' : 'hi',\n"," 'neighbours' : 'neighbor',\n"," 'hmu' : 'hit me up',\n"," 'twinsies' : 'twins',\n"," '“what' : 'what',\n"," 'inb4' : 'in before',\n"," 'halflife' : 'half life',\n"," 'heyy' : 'hey',\n"," 'summarise' : 'summarize',\n"," 'lpt' : 'life pro tip',\n"," 'gofundme' : 'go find me',\n"," '5yearold' : '5 year old',\n"," 'noyou' : 'no you',\n"," 'yesyou' : 'yes you',\n"," 'life\".' : 'life',\n"," 'yess' : 'yes',\n"," 'greys' : 'gray',\n"," 'daynight' : 'day night',\n"," 'yessss' : 'yes',\n"," 'trickortreating' : 'trick or treat',\n"," 'ninenine' : 'nine nine',\n"," 'dnd' : 'do not disturb',\n"," 'howre' : 'how are',\n"," 'highfive' : 'high five',\n"," 'favour' : 'favor',\n"," 'gtfo' : 'Get the fuck out',\n"," 'necessarythey' : 'necessary they',\n"," 'yessssss' : 'yes',\n"," 'jaja' : 'haha',\n"," 'stopdinner' : 'stop dinner',\n"," 'wristbander' :  'wrist bander',\n"," 'tf2' : 'team fortress',\n"," 'ptsd' : 'post traumatic stress disorder',\n"," 'whataburger' : 'what a burger',\n"," 'youi' : 'you i',\n"," 'nosleep' : 'no sleep',\n"," 'warframe' : 'war frame',\n"," 'what?*' : 'what',\n"," 'yoooo' : 'yes',\n"," 'lul' : 'love you lots',\n"," 'pmed' : 'private messaged',\n"," ':&gt' : 'get through',\n"," 'pmd' : 'private messaged',\n"," 'ahahah' : 'haha',\n"," 'rsuddenlygay' : 'suddenly gay',\n"," 'rsuicidebywords' : 'suicide by words',\n"," 'rmadlads' :'mad lads',\n"," '“oh' : 'oh',\n"," 'i‘m' : 'i am',\n"," 'raww' : 'raw',\n"," 'clickbait' : 'click bait',\n"," 'rshowerthoughts' : 'shower thoughts',\n"," 'ymmv' : 'your mileage may vary',\n"," 'imnsho' : 'in my not so humble opinion',\n"," 'shittttt' : 'shit',\n"," 'holllyyyyyyy' : 'holy',\n"," 'foxygen' : 'oxygen',\n"," 'rteenagers' : 'teenagers',\n"," 'gotchu' : 'got you',\n"," 'boredwho' : 'bored who',\n"," 'gt;: ' : 'get through',\n"," 'coldplay' : 'cold play',\n"," 'crosspost' : 'cross post',\n"," ' #tellyourstoryin5words' : 'tell your story in 5 words',\n"," 'isare' : 'is are',\n"," 'sfw' : 'safe for work',\n"," 'downvoting' :  'down voting',\n"," 'rpointlessstories' : 'pointless stories',\n"," 'now?!' : 'now',\n"," 'apologise' : 'apologize',\n"," '“they' : 'they',\n"," 'enough’.' : 'enough',\n"," 'goodcool' : 'good cool',\n"," 'gtgt': 'got to go to',\n"," '‘not' : 'not',\n"," 'upvoter' : 'up voter',\n"," 'breathtakingyour' :  'breath taking our',\n"," 'runexpectedoffice' : 'unexpected office',\n"," 'leavingbi' : 'leaving',\n"," 'rfoundthemobileuser' : 'found the mobile user',\n"," 'thanksif' : 'thanks if',\n"," 'rwholesome' : 'wholesome',\n"," 'lol' : 'laugh out loud',\n"," 'rlounge' : 'lounge',\n"," 'soundcloud' : 'sound cloud',\n"," 'leppard' : 'leopard',\n"," 'rtotallynotrobots' : 'totally not robots',\n"," 'cavetown' : 'cave town',\n"," 'blinddisabled' : 'blind disabled',\n"," 'introverting' : 'introvert',\n"," 'lmaoooo' : 'laughing my ass off',\n"," 'yh' : 'yes',\n"," 'sucks!\"america' : 'sucks america',\n"," 'fawlty' : 'faulty',\n"," 'runpopularopinion' : 'run popular opinion',\n"," 'yesssss' : 'yes',\n"," 'crossdress' : 'cross dress',\n"," 'adminsemployees' : 'admins employees',\n"," 'smokedis' : 'smoke',\n"," 'spelt' : 'spell',\n"," '“far' : 'far',\n"," 'dayweekmonth' : 'day week month',\n"," 'thicc' : 'thick',\n"," 'yaaay' : 'yes',\n"," 'suckswhats' : 'sucks what',\n"," 'durnk' : 'drunk',\n"," 'butterfinger' : 'butter finger',\n"," 'tekken' : 'taken',\n"," 'yayyyy' : 'yes',\n"," 'recall': 'recall',\n"," 'lotr' : 'lord of the rings',\n"," 'mhm' : 'yes',\n"," 'travelled' : 'travel',\n"," 'lolyou' : 'laugh out loud you',\n"," 'rlifeprotips' : 'life pro tips',\n"," 'itwhat' : 'it what',\n"," 'rwallstreetbets' : 'wall street bets',\n"," 'sharptooth' : 'sharp tooth',\n"," 'vsauce' : 'sauce',\n"," 'yayyy' : 'yes',\n"," 'casualconversation' : 'casual conversation',\n"," 'world war 2' : 'world war 2',\n"," 'hiiii' : 'hi',\n"," 'no3' : 'no',\n"," 'selfie' : 'selfie',\n"," 'dreamworks' : 'dream works',\n"," 'bf4' : 'before',\n"," 'hej' : 'hi',\n"," 'flavoured' : 'flavored',\n"," 'daaamn' : 'damn',\n"," 'son' : 'son',\n"," 'you' : 'you',\n"," 'gay\".' : 'gay',\n"," 'nword' : 'word',\n"," 'rthedavincicode' : 'the vinci code',\n"," 'brexit' : 'brexit',\n"," 'midtwenties' : 'mid twenties',\n"," 'bingewatch' : 'binge watch',\n"," 'peel”.' : 'peel',\n"," 'yourselfwell' : 'yourself well',\n"," 'yppah' : 'yes',\n"," 'rbisexual' : 'bisexual',\n"," 'kindda' : 'kind of',\n"," 'runderratedcomments' : 'underrated comments',\n"," 'backmaybe' : 'back may be',\n"," 'itbut' : 'it but',\n"," 'suggestionsi' : 'suggestions',\n"," 'motherfuckerglad' : 'mother fucker glad',\n"," 'nvm' : 'never mind',\n"," 'songshelp' : 'songs help',\n"," 'positivityfun' : 'positivity fun',\n"," 'indoorone' : 'indore one',\n"," 'timehow' : 'time how',\n"," 'lolbut' : 'laugh out loud but',\n"," 'manwoman' : 'man woman',\n"," 'feelingdoing' : 'feeling doing',\n"," 'friendscould' : 'friends cloud',\n"," 'rhappyrelationships' : 'happy relationships',\n"," 'do. Lonely' : 'do lonely',\n"," 'realisation' : 'realization',\n"," 'woooow' : 'wow',\n"," 'rcatsstandingup' : 'cats standing up',\n"," 'goldenboye' : 'golden boy',\n"," 'weeki' : 'week',\n"," 'numbah' : 'number',\n"," 'yeahh' : 'yes',\n"," 'youim' : 'you i am',\n"," 'toowhat' : 'too what',\n"," 'deffinetly' : 'definitely',\n"," 'game3' : 'game',\n"," 'xpost' : 'post',\n"," 'rchildfree' : 'child free',\n"," 'music2' : 'music',\n"," 'quotebook' : 'quote book',\n"," 'ufuckswithducks' : 'fuck with duck',\n"," 'lold' : 'old',\n"," 'whaaaaat' : 'what',\n"," 'flavours' : 'flavors',\n"," 'rpics' : 'pictures',\n"," 'piano2' : 'piano',\n"," 'requirementsi' : 'requirements',\n"," 'himher' : 'him her',\n"," 'yeaaah' : 'yes',\n"," 'rsuicidewatch' : 'suicide watch',\n"," 'damnnnn' : 'damn',\n"," 'longsword' : 'long word',\n"," 'awfuli' : 'awefully',\n"," 'humour' : 'humor',\n"," 'fooddrink' : 'food drink',\n"," 'hby' : 'how about you',\n"," 'roomwhat' : 'room what',\n"," 'selfies' : 'selfie',\n"," 'feelsbadman' : 'feels bad man',\n"," 'youuu' : 'you',\n"," 'mustnt' : 'must not',\n"," 'nederlands' : 'netherlands',\n"," 'aaaaand' : 'and',\n"," 'smoll' : 'small',\n"," 'yus' : 'yes',\n"," 'madlad' : 'mad lad',\n"," 'rniceguys' : 'nice guys',\n"," 'uyourearealcunt' : ' you are a real cunt',\n"," 'rimsorryjon' : 'i am sorry jon',\n"," 'yet.\"' : 'yet',\n"," 'edit😬' : 'edit',\n"," 'retreival' : 'retrieval',\n"," 'haaaaate' : 'hate',\n"," 'musicianband' : 'musician band',\n"," 'wingies' : 'wings',\n"," 'money4' : 'money',\n"," 'work2' : 'work',\n"," 'goodi' : 'good',\n"," 'touchstarved' : 'touch starved',\n"," 'grindr' : 'grinder',\n"," 'rblunderyears' : 'blunder years',\n"," 'rcursedcomments' : 'cursed comments',\n"," '‘em' : 'them',\n"," 'rstaticsnake' : 'static snake',\n"," 'marcy' : 'mercy',\n"," 'mightve' : 'might have',\n"," 'cuteits' : 'cute',\n"," 'whatim' : 'what i am',\n"," 'havingfun' : 'having fun',\n"," 'exwifes' : 'ex wives',\n"," 'noyoure' : 'no you are',\n"," 'aaaaand' : 'and',\n"," 'smoll' : 'small',\n"," 'yus' : 'yes',\n"," \"i'hv\": \"i have\",\n"," \"i'll\": \"i will\",\n"," '☺️':'😊',\n"," 'ampx###b': 'amp bitch',\"i've\": 'i have','rwholesomememes':'wholesome memes',\n"," 'hello😀😊☺🙌👍':'hello 😀 😊','͜ʖ': '😊', '😂😂':'😂','😂😂😂':'😂','ayyyy':'yes','\\U0001f970':'😊', '🅱️ailure' : 'big failure', \"goin'\": 'going','👉😎👉': '😎', \"d'aww\" : 'so cute','ulionghost': ' you lion ghost',\"fuckin'\": 'fucking', 'uiwinalot7': ' you i win a lot', 'goodra': 'good',\n","'pie5': 'being soft', '😀😊☺': '😀', 'uwaterguy##': ' you water guy', ' rseriousconversation': 'serious conversation','runexpectedfactorial':'unexpected factorial', \"i'mma\": 'i am',\n","'👏👏':'👏', \"lol'd\": \"laughed out loud\", 'ಠಠ': '😎', 'rtea': 'tea', '🤣🤣🤣': '🤣','👏👏👏':'👏',\"you'\": 'you', \"d'aw\": 'so cute', 'pmmeyogurtpics':'send me yogurt pictures',\n","\"sirma'am\": 'sir madam','rusernamechecksout': 'user name checks out', 'lt3lt3lt3': 'love', 'bookmovie': 'book movie', '😀😊☺🤗😇': '😀 😊 🤗 😇',\n","'rpopping': 'popping','gt##': 'got to go', 'rwoooosh': 'woooosh', 'rr4r': 'redditor for redditor','ustaticsnake': 'you static snake','eli5':'explain in simple words',\n","'mrbeast': 'beast', 'rkarmaroulette':'karma roulette','😭😭':'😭','️\\U0001f9e1💛💚💙💜':'love','🤔🤔🤔':'🤔','rgatekeeping':'gate keeping', 'moviestv': 'movie television','dinozo':'dinosaur', 'scarn': 'mayhem',\n","'\\U0001f9e1💛💚💙💜': 'love', \"pm'd\":'messaged','ayyye':'yes', '\\U0001f92a':'😀', 'gtno': 'get the fuck out', \"walkin'\": 'walking', 'rknightsofpineapple':'knights of pineapple',\n","'##what': 'what','rbrandnewsentence':'brand new sentence', 'bhosadiwale':'son of a bitch', 'runexpectedthanos': 'unexpected thanos',\"'murica\": 'america',\n","'udonaldduck':'you donald duck','rjobs':'jobs' ,'uitsthesnake': 'it is the snake','💕💕': '💕'}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iup1xfrZ_mW-"},"source":["Pre-processing functions"]},{"cell_type":"code","metadata":{"id":"4pCHRvwZKPX3"},"source":["def clean_contractions(text, mapping):\n","    specials = [\"’\", \"‘\", \"´\", \"`\"]\n","    for s in specials:\n","        text = text.replace(s, \"'\")\n","    text = ' '.join([mapping[t] if t in mapping else mapping[t.lower()] if t.lower() in mapping else t for t in text.split(\" \")])\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iILBdiGBKpwc"},"source":["def clean_special_chars(text, punct, mapping):\n","    for p in mapping:\n","        text = text.replace(p, mapping[p])\n","    \n","    for p in punct:\n","        text = text.replace(p, '')\n","    \n","    specials = {'\\u200b': ' ', '…': ' ', '\\ufeff': ''}  # to be updated again upon checking the coverage\n","    for s in specials:\n","        text = text.replace(s, specials[s])\n","    \n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5l5s6DaKpsQ"},"source":["def remove_newlines(sent):\n","  sent = re.sub(r'\\s+', \" \", sent )\n","  return sent"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HjvxT4EcKppa"},"source":["def clean_numbers(x):\n","    if bool(re.search(r'\\d', x)):\n","        x = re.sub('[0-9]{5,}', '#####', x)\n","        x = re.sub('[0-9]{4}', '####', x)\n","        x = re.sub('[0-9]{3}', '###', x)\n","        x = re.sub('[0-9]{2}', '##', x)\n","        #x = re.sub('[0-9]', '#', x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OT14viu9KpmJ"},"source":["def clean_missplets(text, mapping):\n","    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WjAXkVj6_4e5"},"source":["Data Loading"]},{"cell_type":"code","metadata":{"id":"wHpSxqq4KpkS"},"source":["# fetching data from csv file to dataframe\n","reddit = pd.read_csv('/content/drive/My Drive/Data/Conversations/casual_data_windows.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"qIUkTJ1W-Bni","executionInfo":{"status":"ok","timestamp":1615816153386,"user_tz":-330,"elapsed":514,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"a4cd8abf-947c-4aa6-b6f0-86385c0c9e81"},"source":["reddit.head(2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>What kind of phone(s) do you guys have?</td>\n","      <td>I have a pixel. It's pretty great. Much better...</td>\n","      <td>Does it really charge all the way in 15 min?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>I have a pixel. It's pretty great. Much better...</td>\n","      <td>Does it really charge all the way in 15 min?</td>\n","      <td>Pretty fast. I've never timed it, but it's und...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  ...                                                  2\n","0           0  ...       Does it really charge all the way in 15 min?\n","1           1  ...  Pretty fast. I've never timed it, but it's und...\n","\n","[2 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"QlCVZD8tKphD"},"source":["# creating an empty dataframe to hold consecutive conversation-pairs\n","df_conv = pd.DataFrame(columns=['sent1', 'sent2'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q4rCapJ8KpeR"},"source":["# filling the dataframe with conversation pairs from reddit dataframe\n","for index, row in reddit.iterrows():\n","    df_conv = df_conv.append({'sent1':row[\"0\"],'sent2':row[\"1\"]},ignore_index=True)\n","    df_conv = df_conv.append({'sent1':row[\"1\"],'sent2':row[\"2\"]},ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gpfks_uhADCU"},"source":["Data cleansing activities"]},{"cell_type":"code","metadata":{"id":"NzG8fQCoh1bY"},"source":["df_conv['sent1'] = df_conv['sent1'].apply(lambda x: clean_contractions(x, contraction_mapping))\n","df_conv['sent2'] = df_conv['sent2'].apply(lambda x: clean_contractions(x, contraction_mapping))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"daJfHJmvh1Gn"},"source":["df_conv['sent1'] = df_conv['sent1'].apply(lambda x: clean_special_chars(x, punct, punct_mapping))\n","df_conv['sent2'] = df_conv['sent2'].apply(lambda x: clean_special_chars(x, punct, punct_mapping))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X5DcS47qLYOl"},"source":["df_conv['sent1'] = df_conv['sent1'].apply(lambda x: clean_contractions(x, contraction_mapping))\n","df_conv['sent2'] = df_conv['sent2'].apply(lambda x: clean_contractions(x, contraction_mapping))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dO5s6d81LYMk"},"source":["df_conv['sent1'] = df_conv['sent1'].apply(lambda x : x.lower())\n","df_conv['sent2'] = df_conv['sent2'].apply(lambda x : x.lower())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s07YlBENGez8"},"source":["df_conv['sent1'] = df_conv['sent1'].apply(lambda x : remove_newlines(x))\n","df_conv['sent2'] = df_conv['sent2'].apply(lambda x : remove_newlines(x))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5xe2Nu3xLYJC"},"source":["df_conv['sent1'] = df_conv['sent1'].apply(lambda x: clean_numbers(x))\n","df_conv['sent2'] = df_conv['sent2'].apply(lambda x: clean_numbers(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g1V9rPJ4MqhF"},"source":["df_conv['sent1'] = df_conv['sent1'].apply(lambda x: clean_numbers(x))\n","df_conv['sent2'] = df_conv['sent2'].apply(lambda x: clean_numbers(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NBl_6ialM6au"},"source":["df_conv['sent1'] = df_conv['sent1'].apply(lambda x: clean_missplets(x, missplet_dict))\n","df_conv['sent2'] = df_conv['sent2'].apply(lambda x: clean_missplets(x, missplet_dict))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LrKMniUxMqdV","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1615816590868,"user_tz":-330,"elapsed":514,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"3594d026-0fdb-4b65-8b50-10e76cd5a331"},"source":["print(df_conv.shape)\n","df_conv.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(112594, 2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sent1</th>\n","      <th>sent2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>what kind of phones do you guys have</td>\n","      <td>i have a pixel it is pretty great much better ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>i have a pixel it is pretty great much better ...</td>\n","      <td>does it really charge all the way in ## min</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>i have a pixel it is pretty great much better ...</td>\n","      <td>does it really charge all the way in ## min</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>does it really charge all the way in ## min</td>\n","      <td>pretty fast i have never timed it but it is un...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>does it really charge all the way in ## min</td>\n","      <td>pretty fast i have never timed it but it is un...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               sent1                                              sent2\n","0               what kind of phones do you guys have  i have a pixel it is pretty great much better ...\n","1  i have a pixel it is pretty great much better ...        does it really charge all the way in ## min\n","2  i have a pixel it is pretty great much better ...        does it really charge all the way in ## min\n","3        does it really charge all the way in ## min  pretty fast i have never timed it but it is un...\n","4        does it really charge all the way in ## min  pretty fast i have never timed it but it is un..."]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"xR7ZSnZbMqZ7"},"source":["duplicateRowsDF = df_conv[df_conv.duplicated()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D799ZBhZMqXj"},"source":["# removing duplicate rows\n","df_conv = df_conv.drop_duplicates(subset=None, keep='first', inplace=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vqhgEXaMqUW","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1615816594785,"user_tz":-330,"elapsed":788,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"d2361f7b-e80f-429e-cba8-c3ae4ff4e2b5"},"source":["print(df_conv.shape)\n","df_conv.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(71052, 2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sent1</th>\n","      <th>sent2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>what kind of phones do you guys have</td>\n","      <td>i have a pixel it is pretty great much better ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>i have a pixel it is pretty great much better ...</td>\n","      <td>does it really charge all the way in ## min</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>does it really charge all the way in ## min</td>\n","      <td>pretty fast i have never timed it but it is un...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>pretty fast i have never timed it but it is un...</td>\n","      <td>cool i have been thinking of getting one my ph...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>what kind of phones do you guys have</td>\n","      <td>samsung galaxy j1 it is my first cell phone an...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               sent1                                              sent2\n","0               what kind of phones do you guys have  i have a pixel it is pretty great much better ...\n","1  i have a pixel it is pretty great much better ...        does it really charge all the way in ## min\n","3        does it really charge all the way in ## min  pretty fast i have never timed it but it is un...\n","5  pretty fast i have never timed it but it is un...  cool i have been thinking of getting one my ph...\n","6               what kind of phones do you guys have  samsung galaxy j1 it is my first cell phone an..."]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"3sQDZkhqAvbE"},"source":["Word to index dictionary creation for our dataset"]},{"cell_type":"code","metadata":{"id":"viALvQqsMqSB"},"source":["# filtering out unique sentence set from conversation pairs. this is needed to be done before creating word to index dictionary\n","\n","sent1 = df_conv['sent1']\n","sent2 = df_conv['sent2']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GOf8IiPJMqPy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615816598777,"user_tz":-330,"elapsed":716,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"2b097db8-bdb9-49c7-89cb-ba4b489ac1fd"},"source":["import torch\n","\n","SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f9ab6a78950>"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MvY0ZUO0Kv4f","executionInfo":{"status":"ok","timestamp":1615816607017,"user_tz":-330,"elapsed":7747,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"af0c50b6-1b67-4fa8-9e03-8606db5f61af"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n","\u001b[K     |████████████████████████████████| 1.9MB 6.7MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 53.0MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 53.8MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=84710e382f7a62419bb3b4aec8ee9fb87c19dc6f25b309b33674d41affb66f8e\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mVG2pK32JIuW","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["fb866213ee5d4b028f9cae38f6bfbb95","c7adc0701d3c43beadfb0a20b14c195c","07823a28544447fabf67076386526043","22120f1dcdb14de299f3b888a0879fdc","d247dd05126447138ccd31faad561306","706e481d992a40ada71c3187ec945407","77a4c0502a374e8290cee083e4e2aa95","f2a431b80e8a4b9995db704129cb8408"]},"executionInfo":{"status":"ok","timestamp":1615816607719,"user_tz":-330,"elapsed":5055,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"533d8124-0e80-4246-9c3f-746a442ccd2c"},"source":["import transformers\n","from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb866213ee5d4b028f9cae38f6bfbb95","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DEF8hYatKd-J","executionInfo":{"status":"ok","timestamp":1615816610381,"user_tz":-330,"elapsed":722,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"a3ecd7d6-1119-436a-ede6-cdde79d3a4a7"},"source":["len(tokenizer.vocab)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30522"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wf4FnrAYLQxM","executionInfo":{"status":"ok","timestamp":1615816613553,"user_tz":-330,"elapsed":752,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"bea9a015-3f4f-47c3-d4fc-bfdc9a1ccbf2"},"source":["init_token = tokenizer.cls_token\n","eos_token = tokenizer.sep_token\n","pad_token = tokenizer.pad_token\n","unk_token = tokenizer.unk_token\n","\n","print(init_token, eos_token, pad_token, unk_token)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[CLS] [SEP] [PAD] [UNK]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D3bBbYnaLWRQ","executionInfo":{"status":"ok","timestamp":1615816614763,"user_tz":-330,"elapsed":625,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"3bb5c858-f31a-4c68-d8c9-0871ade00ee7"},"source":["init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n","eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n","pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n","unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n","\n","print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["101 102 0 100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zrXlqVOoLhuB","executionInfo":{"status":"ok","timestamp":1615816615918,"user_tz":-330,"elapsed":547,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"448d8451-9698-4a41-9114-7b040eda7ae0"},"source":["max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n","\n","print(max_input_length)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["512\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cXE-ZKxNLp56"},"source":["def tokenize_and_cut(sentence):\n","    tokens = tokenizer.tokenize(sentence) \n","    tokens = tokens[:max_input_length-2]\n","    return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCacC8sGLtBt"},"source":["from torchtext.legacy import data\n","\n","sent1 = data.Field(batch_first = True,\n","                  use_vocab = False,\n","                  tokenize = tokenize_and_cut,\n","                  preprocessing = tokenizer.convert_tokens_to_ids,\n","                  init_token = init_token_idx,\n","                  eos_token = eos_token_idx,\n","                  pad_token = pad_token_idx,\n","                  unk_token = unk_token_idx)\n","\n","sent2 = data.Field(batch_first = True,\n","                  use_vocab = False,\n","                  tokenize = tokenize_and_cut,\n","                  preprocessing = tokenizer.convert_tokens_to_ids,\n","                  init_token = init_token_idx,\n","                  eos_token = eos_token_idx,\n","                  pad_token = pad_token_idx,\n","                  unk_token = unk_token_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"19d52grhLwht"},"source":["train_data , valid_data = train_test_split(df_conv,test_size = 0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"7oHsJLvFMfoX","executionInfo":{"status":"ok","timestamp":1615816621622,"user_tz":-330,"elapsed":764,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"b1b612e0-ce8e-4f81-ba7f-74db497f40d5"},"source":["%cd '/content/drive/My Drive/Data/Conversations/'\n","\n","%pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Data/Conversations\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Data/Conversations'"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"m9OU33VHMkYc"},"source":["train_data.to_csv('train.csv',index = False)\n","valid_data.to_csv('test.csv',index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-KcHygSnMmyt"},"source":["data_fields = [('sent1',sent1),('sent2',sent2)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"znpntu9yMrBA"},"source":["# TabularDataset(Dataset):Defines a Dataset of columns stored in CSV, TSV, or JSON format.\n","# Create a TabularDataset given a path, file format, and field list\n","\n","train_data , valid_data = TabularDataset.splits(path ='/content/drive/My Drive/Data/Conversations/' ,train='train.csv', test ='test.csv', format='csv', fields=data_fields)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIUQAtNiMtkZ","executionInfo":{"status":"ok","timestamp":1615816666393,"user_tz":-330,"elapsed":745,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"b82a8593-9662-4856-d16e-6494ee7e9c59"},"source":["print(f\"Number of training examples: {len(train_data)}\")\n","print(f\"Number of testing examples: {len(valid_data)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of training examples: 56842\n","Number of testing examples: 14212\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2_Oq1BlJM_SI","executionInfo":{"status":"ok","timestamp":1615816667931,"user_tz":-330,"elapsed":753,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"3bf7f627-1069-43c2-80da-141736b65964"},"source":["print(vars(train_data.examples[6]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'sent1': [2073, 2515, 3071, 2444, 1045, 2444, 1999, 5862, 11333], 'sent2': [2141, 1999, 14700, 4058, 2444, 1999, 8770, 4058, 2005, 1996, 2293, 1997, 2643, 2131, 2033, 2041, 1997, 4058]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24to3yU_Ncd0","executionInfo":{"status":"ok","timestamp":1615816669135,"user_tz":-330,"elapsed":622,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"e18ae39c-b7d3-4ed7-c159-7499785baa7e"},"source":["tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6])['sent1'])\n","\n","print('Sent1 tokens:',tokens)\n","\n","tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6])['sent2'])\n","\n","print('Sent2 tokens:',tokens)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sent1 tokens: ['where', 'does', 'everyone', 'live', 'i', 'live', 'in', 'seattle', 'wa']\n","Sent2 tokens: ['born', 'in', 'dayton', 'ohio', 'live', 'in', 'canton', 'ohio', 'for', 'the', 'love', 'of', 'god', 'get', 'me', 'out', 'of', 'ohio']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RoOveaX_Ni8A"},"source":["# building vocabulary for the responses(sent2)\n","sent2.build_vocab(train_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVZFNY88Z4LW","executionInfo":{"status":"ok","timestamp":1615816671708,"user_tz":-330,"elapsed":516,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"7c811a47-ef47-4b1b-e943-5742ff582696"},"source":["len(sent2.vocab)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15183"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"DMBV9JJ_OaNL"},"source":["from torchtext.legacy.data import BucketIterator,TabularDataset\n","\n","BATCH_SIZE = 128\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data), \n","    batch_size = BATCH_SIZE, \n","    device = device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i7eF2iZzOmFl","colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["5882ff380fae417ab5ce2913b710c189","54b27e2d2dec4d1caab0996e999bbc2a","8d54fe1d82654cfb9a429a11315d5b0a","bfee81ff4dd94d278e15ac121e7056dd","70abe934f6f94a5cbde177523d2f8a90","675d2a83b5d8480080675859740649b2","02628033efb0456aa305f653532bae9c","7a616df17a584433a7457df21a65846c","1cbbfe48a8a34cd38f3eea263edad7c5","7b42fed2bf6a4f998e53ffddf14ed505","a2dee824b24a4db1ba4f44261eb8871f","5495a110ee3d4f0e99c28cb559715fd6","4eeadd0a9dfb468ca08abe3daf787563","d1e877ce36754b09a380472155c8a3db","c88d12a91d894734a5951c73d9413789","7495882d94444e1bb401eed94a0a6ac1"]},"executionInfo":{"status":"ok","timestamp":1615816685851,"user_tz":-330,"elapsed":12190,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"158df355-99bd-4baf-e356-4633e2e722b4"},"source":["from transformers import BertTokenizer, BertModel\n","\n","bert = BertModel.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5882ff380fae417ab5ce2913b710c189","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1cbbfe48a8a34cd38f3eea263edad7c5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9EzujwZYROWl"},"source":["# Encoder\n","\n","class Encoder(nn.Module):\n","    def __init__(self, bert, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","\n","        self.bert = bert\n","        \n","        emb_dim = bert.config.to_dict()['hidden_size']\n","              \n","        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, batch_first = True,dropout = dropout)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, sent1):\n","        \n","        #sent1 = [sent1 len, batch size]\n","        \n","        with torch.no_grad():\n","            embedded = self.bert(sent1)[0]\n","        \n","        #embedded = [sent1 len, batch size, emb dim]\n","        \n","        outputs, (hidden, cell) = self.rnn(embedded)\n","        \n","        #outputs = [sent1 len, batch size, hid dim * n directions]\n","        #hidden = [n layers * n directions, batch size, hid dim]\n","        #cell = [n layers * n directions, batch size, hid dim]\n","        \n","        #outputs are always from the top hidden layer\n","        \n","        return hidden, cell"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IX4mWCTMRR52"},"source":["# Decoder\n","\n","class Decoder(nn.Module):\n","    def __init__(self, bert, hid_dim, output_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        self.output_dim = output_dim\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.bert = bert        \n","        emb_dim = bert.config.to_dict()['hidden_size']\n","        \n","        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, batch_first = True, dropout = dropout)\n","        \n","        self.fc_out = nn.Linear(hid_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","\n","\n","    def forward(self, input, hidden, cell):\n","        \n","        #input = [batch size]\n","        #hidden = [n layers * n directions, batch size, hid dim]\n","        #cell = [n layers * n directions, batch size, hid dim]\n","        \n","        #n directions in the decoder will both always be 1, therefore:\n","        #hidden = [n layers, batch size, hid dim]\n","        #context = [n layers, batch size, hid dim]\n","        \n","        input = input.unsqueeze(0)\n","        \n","        #input = [1, batch size]\n","        \n","        with torch.no_grad():\n","            embedded = self.bert(input)[0]\n","        \n","        #embedded = [1, batch size, emb dim]\n","                \n","        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","        \n","        #output = [seq len, batch size, hid dim * n directions]\n","        #hidden = [n layers * n directions, batch size, hid dim]\n","        #cell = [n layers * n directions, batch size, hid dim]\n","        \n","        #seq len and n directions will always be 1 in the decoder, therefore:\n","        #output = [1, batch size, hid dim]\n","        #hidden = [n layers, batch size, hid dim]\n","        #cell = [n layers, batch size, hid dim]\n","        \n","        prediction = self.fc_out(output.squeeze(0))\n","        \n","        #prediction = [batch size, output dim]\n","        \n","        return prediction, hidden, cell"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"89DE_7KeRR96"},"source":["# Seq2seq\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","        assert encoder.hid_dim == decoder.hid_dim, \\\n","            \"Hidden dimensions of encoder and decoder must be equal!\"\n","        assert encoder.n_layers == decoder.n_layers, \\\n","            \"Encoder and decoder must have equal number of layers!\"\n","        \n","    def forward(self, sent1, sent2, teacher_forcing_ratio = 0.5):\n","        \n","        #sent1 = [sent1 len, batch size]\n","        #sent2 = [sent2 len, batch size]\n","        #teacher_forcing_ratio is probability to use teacher forcing\n","        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n","        \n","        batch_size = sent2.shape[1]\n","        sent2_len = sent2.shape[0]\n","        sent2_vocab_size = self.decoder.output_dim\n","        \n","        #tensor to store decoder outputs\n","        outputs = torch.zeros(sent2_len, batch_size, sent2_vocab_size).to(self.device)\n","        \n","        #last hidden state of the encoder is used as the initial hidden state of the decoder\n","        hidden, cell = self.encoder(sent1)\n","        \n","        #first input to the decoder is the <sos> tokens\n","        input = sent2[0,:]\n","        \n","        for t in range(1, sent2_len):\n","            \n","            #insert input token embedding, previous hidden and previous cell states\n","            #receive output tensor (predictions) and new hidden and cell states\n","            output, hidden, cell = self.decoder(input, hidden, cell)\n","            \n","            #place predictions in a tensor holding predictions for each token\n","            outputs[t] = output\n","            \n","            #decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            #get the highest predicted token from our predictions\n","            top1 = output.argmax(1) \n","            \n","            #if teacher forcing, use actual next token as next input\n","            #if not, use predicted token\n","            input = sent2[t] if teacher_force else top1\n","        \n","        return outputs\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yXhd-aJuZl_B"},"source":["OUTPUT_DIM = len(sent2.vocab)\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 256\n","HID_DIM = 512\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","enc = Encoder(bert, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(bert, HID_DIM, OUTPUT_DIM, N_LAYERS, DEC_DROPOUT)\n","\n","model = Seq2Seq(enc, dec, device).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oWftVt-iRSDV","executionInfo":{"status":"ok","timestamp":1615816704383,"user_tz":-330,"elapsed":11344,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"42918be1-fb2c-464f-fd2d-32ccbcc6d1ef"},"source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.uniform_(param.data, -0.08, 0.08)\n","        \n","model.apply(init_weights)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (rnn): LSTM(768, 512, num_layers=2, batch_first=True, dropout=0.5)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (rnn): LSTM(768, 512, num_layers=2, batch_first=True, dropout=0.5)\n","    (fc_out): Linear(in_features=512, out_features=15183, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UHSwVmYvYx0c","executionInfo":{"status":"ok","timestamp":1615816706637,"user_tz":-330,"elapsed":754,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"ba086d56-968e-46d2-f489-2d11106c8971"},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The model has 126,724,687 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y-9127_iRSHe"},"source":["optimizer = optim.Adam(model.parameters())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c1e9P465Yx6f"},"source":["SENT2_PAD_IDX = pad_token_idx\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = SENT2_PAD_IDX)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"edQrckvvRSKY"},"source":["def train(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        sent1 = batch.sent1\n","        sent2 = batch.sent2\n","        \n","        optimizer.zero_grad()\n","        \n","        output = model(sent1, sent2)\n","        \n","        #sent2 = [sent2 len, batch size]\n","        #output = [sent2 len, batch size, output dim]\n","        \n","        output_dim = output.shape[-1]\n","        \n","        output = output[1:].view(-1, output_dim)\n","        sent2 = sent2[1:].view(-1)\n","        \n","        #sent2 = [(sent2 len - 1) * batch size]\n","        #output = [(sent2 len - 1) * batch size, output dim]\n","        \n","        loss = criterion(output, sent2)\n","        \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DwywQbwRYyAK"},"source":["def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            sent1 = batch.sent1\n","            sent2 = batch.sent2\n","\n","            output = model(sent1, sent2, 0) #turn off teacher forcing\n","\n","            #sent2 = [sent2 len, batch size]\n","            #output = [sent2 len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","            \n","            output = output[1:].view(-1, output_dim)\n","            sent2 = sent2[1:].view(-1)\n","\n","            #sent2 = [(sent2 len - 1) * batch size]\n","            #output = [(sent2 len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, sent2)\n","            \n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NNQ-QNBNRSOT"},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"yn0Ms6lRYyGL","executionInfo":{"status":"error","timestamp":1615816719843,"user_tz":-330,"elapsed":3160,"user":{"displayName":"ninja turtle","photoUrl":"","userId":"08410201356610850962"}},"outputId":"05878518-2dd7-4fef-a066-fd5edbd7b2c5"},"source":["N_EPOCHS = 1\n","CLIP = 1\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut1-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-472071541d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-60-a45c516ee5fe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#sent2 = [sent2 len, batch size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-54-3587ff3308be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent1, sent2, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m#insert input token embedding, previous hidden and previous cell states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m#receive output tensor (predictions) and new hidden and cell states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m#place predictions in a tensor holding predictions for each token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-53-a0f5d14847f2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, cell)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#embedded = [1, batch size, emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#output = [seq len, batch size, hid dim * n directions]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0;32m--> 607\u001b[0;31m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    608\u001b[0m         self.check_hidden_size(hidden[1], self.get_expected_cell_size(input, batch_sizes),\n\u001b[1;32m    609\u001b[0m                                'Expected hidden[1] size {}, got {}')\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    221\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 1, 512), got [2, 128, 512]"]}]},{"cell_type":"code","metadata":{"id":"X1zjKKgMRSSr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yEVSWdRSYyMz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-9w5pR_RSXt"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dsn3EOlARScL"},"source":[""],"execution_count":null,"outputs":[]}]}